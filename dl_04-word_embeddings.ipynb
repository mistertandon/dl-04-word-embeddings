{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\aclImdb_v1.tar.gz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url, untar = True, cache_dir = '.', cache_subdir = '')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\aclImdb\\\\train'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\aclImdb\\\\train\\\\unsup'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "remove_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "seed = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Using 60000 files for training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory('aclImdb/train', validation_split = 0.2, subset = 'training', batch_size = BATCH_SIZE, seed = seed)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds = tf.keras.preprocessing.text_dataset_from_directory('aclImdb/test', validation_split = 0.2, subset = 'validation', batch_size = BATCH_SIZE, seed = seed)\n",
    "validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 b\"I saw the other user comment on this movie and just had to add my own. This movie was terrible. Seeing that Juliette Lewis and Brad Pitt were both in it I took a chance and watched the film that my sister purchased in a one dollar movie bin, and let me tell you, not worth one dollar. Maybe it's because of the fact it is a made-for-TV movie, although I have found many other made-for-TV movies much more enjoyable. The story and dialog are poorly written, and the plot is unbelievable and mediocre at best. The performances were not so bad, but were not enough to carry this film. Lewis plays a girl who gets caught up in these crazy circumstances and never seems to get things right, while Pitt plays this mean nasty character who takes advantage of this poor girl. The only good thing about this film is Lewis' t-shirts which are pretty cool. Do your self a favor and skip it.\"\n",
      "2 b\"1st watched 3/28/2004 - 4 out of 10(Dir-Keith Snyder): Unique but slow moving drama about a detective who is only given one week to live and hires someone to kill him so that he won't go out slowly. Another story within this central theme, is the serial killer that he's tracking down but we really don't get shown much of this side of the story. Scott Wolf does a good job in his role as the detective but when a twist in the story occurs and he decides he doesn't want to be killed, the movie just doesn't go anywhere. A very flat performance by Tim Roth in the role of the assassin doesn't help the story much, and Gabriel Byrne really doesn't do much with his role as the person Wolf works thru to get the killing done. All in all this was a good try at a different kind of thriller but there's not enough heart going into the making of this. There were some obvious small things like editing mistakes that made it clear that not a lot work was put into finishing this but instead it was just put on the movie shelves as soon as it could.\"\n",
      "2 b'I know, Marcel Carn\\xc3\\xa9 is a genius of a filmmaker, the actors in the film are the cream-de-la-cream of French cinema of the 30s an onward, BUT - this film here lacks so much of a coherent storyline that I dropped out about 3/4 of the way.<br /><br />In my humble opinion, a film first and foremost should be intelligent in what it tries to tell. Film-making is storytelling. Art-pour-l\\'art is a pretentious pose. Hiding a week storyline behind \"artful\" filming is a shame.<br /><br />The great Marcel Carn\\xc3\\xa9 obviously made better films than this one. Quai de Brumes, made just one year later (in 1938) is a stand-out example and small wonder it is unforgettable even today. Nobody can ever forget Jean Gabin\\'s both subdued and passionate acting.<br /><br />Here, in Drole de Drame, we have great actors going wild until everything gets absolutely out of control. The classic screwball comedy of a type never seen before in French cinema (and, possibly, never after). The whole is overdone, unfortunately. This makes you cringe and lose interest.'\n",
      "2 b'If you like the original \"Slapshot,\" good acting and a good plot, rent anything else other than this travesty of film-making. However, if you do enjoy bad VD jokes, monotone Steven Baldwin acting and a storyline a kindergartner could poke holes into, then by all means rent \"Slapshot 2: Breaking the Ice.\" Seriously, the only good thing about this film was seeing the original Hanson Brothers reprise their roles, which was not nearly enough to save it. A life-size cardboard cutout of Paul Newman has more acting talent than Steven Baldwin. And I\\'m being generous. Only if you have a severely morbid sense of curiosity would I suggest you watch this film.'\n",
      "2 b\"I was offered a ticket to a screener last Wednesday, and when I heard Don Cheatle was in it, couldn't pass it by. I am not a huge fan of action/suspense/spy movies, but this one was a cut above the normal. It was more intelligent, and delved a bit into motivations, beliefs, etc. of terrorists. I went into the movie cold, with no idea of the plot, and I recommend that. Most write ups I have read give away too much of the twists in the plot, which I was glad I didn't know beforehand. Don Cheatle was excellent, and so was Sa\\xc3\\xafd Taghmaoui. It was also refreshing to see Hollywood recognizing the breadth of Muslim philosophy for once!\"\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(label_batch[i].numpy(), text_batch[i].numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_TUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size = AUTO_TUNE)\n",
    "validation_ds = validation_ds.cache().prefetch(buffer_size = AUTO_TUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[-0.00968832,  0.01585987,  0.03853962, -0.01252273,  0.02247994],\n",
       "       [ 0.01424104,  0.03008163, -0.02072786, -0.0324785 , -0.01261304],\n",
       "       [-0.02801698,  0.01311456, -0.04975003,  0.01070889, -0.04798668]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([1, 2, 3]))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = '!@rad\\\n",
    "gs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'!@radgs'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower = tf.strings.lower(test_string)\n",
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'!@radgs'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_stripped = tf.strings.regex_replace(lower, '<br />', ' ')\n",
    "html_stripped.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'radgs'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_str = tf.strings.regex_replace(html_stripped, '[%s]' % re.escape(string.punctuation), '')\n",
    "final_str.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standarization(test_string):\n",
    "    \n",
    "    lower = tf.strings.lower(test_string)\n",
    "    html_stripped = tf.strings.regex_replace(lower, '<br />', ' ')\n",
    "    final_str = tf.strings.regex_replace(html_stripped, '[%s]' % re.escape(string.punctuation), '')\n",
    "    \n",
    "    return final_str   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(standardize = custom_standarization,\n",
    "                                      max_tokens = vocab_size,\n",
    "                                      output_mode = 'int',\n",
    "                                      output_sequence_length = sequence_length\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.preprocessing.text_vectorization.TextVectorization at 0x1e244c23c70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (None,), types: tf.string>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds = train_ds.map(lambda x, y:x)\n",
    "text_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "[\n",
    "    vectorize_layer,\n",
    "    Embedding(input_dim = vocab_size, output_dim = embedding_dim),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation = 'relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_callback = tf.keras.callbacks.TensorBoard(log_dir = './logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = tf.keras.losses.BinaryCrossentropy(from_logits = True), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 2/59 [>.............................] - ETA: 22s - loss: -1.3809 - accuracy: 0.1714WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1177s vs `on_train_batch_end` time: 0.6463s). Check your callbacks.\n",
      "59/59 [==============================] - 9s 145ms/step - loss: -2.2628 - accuracy: 0.1662 - val_loss: 3.4751 - val_accuracy: 0.5032\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 8s 135ms/step - loss: -5.3217 - accuracy: 0.1662 - val_loss: 7.6262 - val_accuracy: 0.5032\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 8s 140ms/step - loss: -10.9040 - accuracy: 0.1662 - val_loss: 14.7717 - val_accuracy: 0.5032\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: -19.9082 - accuracy: 0.1662 - val_loss: 25.7197 - val_accuracy: 0.5032\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: -33.1087 - accuracy: 0.1662 - val_loss: 41.1989 - val_accuracy: 0.5032\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 8s 138ms/step - loss: -51.2084 - accuracy: 0.1662 - val_loss: 61.8758 - val_accuracy: 0.5032\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 8s 140ms/step - loss: -74.8527 - accuracy: 0.1662 - val_loss: 88.3651 - val_accuracy: 0.5032\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 9s 145ms/step - loss: -104.6392 - accuracy: 0.1662 - val_loss: 121.2369 - val_accuracy: 0.5032\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 9s 152ms/step - loss: -141.1230 - accuracy: 0.1662 - val_loss: 161.0222 - val_accuracy: 0.5032\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 9s 145ms/step - loss: -184.8212 - accuracy: 0.1662 - val_loss: 208.2164 - val_accuracy: 0.5032\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 8s 139ms/step - loss: -236.2172 - accuracy: 0.1662 - val_loss: 263.2820 - val_accuracy: 0.5032\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 8s 140ms/step - loss: -295.7625 - accuracy: 0.1662 - val_loss: 326.6521 - val_accuracy: 0.5032\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 7s 124ms/step - loss: -363.8798 - accuracy: 0.1662 - val_loss: 398.7321 - val_accuracy: 0.5032\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: -440.9651 - accuracy: 0.1662 - val_loss: 479.9020 - val_accuracy: 0.5032\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 8s 132ms/step - loss: -527.3898 - accuracy: 0.1662 - val_loss: 570.5184 - val_accuracy: 0.5032\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 8s 129ms/step - loss: -623.5027 - accuracy: 0.1662 - val_loss: 670.9160 - val_accuracy: 0.5032\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 10s 171ms/step - loss: -729.6309 - accuracy: 0.1662 - val_loss: 781.4097 - val_accuracy: 0.5032\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 9s 146ms/step - loss: -846.0828 - accuracy: 0.1662 - val_loss: 902.2952 - val_accuracy: 0.5032\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 9s 145ms/step - loss: -973.1481 - accuracy: 0.1662 - val_loss: 1033.8521 - val_accuracy: 0.5032\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 8s 142ms/step - loss: -1111.1001 - accuracy: 0.1662 - val_loss: 1176.3428 - val_accuracy: 0.5032\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 8s 143ms/step - loss: -1260.1964 - accuracy: 0.1662 - val_loss: 1330.0160 - val_accuracy: 0.5032\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 8s 140ms/step - loss: -1420.6809 - accuracy: 0.1662 - val_loss: 1495.1057 - val_accuracy: 0.5032\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 8s 138ms/step - loss: -1592.7836 - accuracy: 0.1662 - val_loss: 1671.8344 - val_accuracy: 0.5032\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: -1776.7219 - accuracy: 0.1662 - val_loss: 1860.4126 - val_accuracy: 0.5032\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 9s 144ms/step - loss: -1972.7036 - accuracy: 0.1662 - val_loss: 2061.0400 - val_accuracy: 0.5032\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 9s 156ms/step - loss: -2180.9253 - accuracy: 0.1662 - val_loss: 2273.9067 - val_accuracy: 0.5032\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 9s 149ms/step - loss: -2401.5730 - accuracy: 0.1662 - val_loss: 2499.1938 - val_accuracy: 0.5032\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 9s 151ms/step - loss: -2634.8269 - accuracy: 0.1662 - val_loss: 2737.0735 - val_accuracy: 0.5032\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 9s 147ms/step - loss: -2880.8547 - accuracy: 0.1662 - val_loss: 2987.7107 - val_accuracy: 0.5032\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 9s 145ms/step - loss: -3139.8198 - accuracy: 0.1662 - val_loss: 3251.2632 - val_accuracy: 0.5032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e247c74f10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data = validation_ds, epochs = 30, callbacks = [tensor_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10364), started 0:11:57 ago. (Use '!kill 10364' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6f033cebe9dc3f0c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6f033cebe9dc3f0c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: 10364: No such process\n"
     ]
    }
   ],
   "source": [
    "!kill 10364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "10000\n",
      "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "print(type(vocab))\n",
    "print(len(vocab))\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
